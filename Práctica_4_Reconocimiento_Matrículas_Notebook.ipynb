{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4: Reconocimiento de Matrículas\n",
    "\n",
    "Este notebook implementa un prototipo de reconocimiento de matrículas de vehículos en video. Los objetivos de esta práctica incluyen la detección y seguimiento de personas y vehículos, el reconocimiento de matrículas visibles en los vehículos, y la exportación de los resultados en un video y un archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "La práctica se enfoca en desarrollar un sistema de detección y reconocimiento de objetos que cumpla con los siguientes requisitos:\n",
    "\n",
    "- Detección y seguimiento: Identificación y rastreo de personas y vehículos presentes en el video.\n",
    "- Reconocimiento de matrículas: Detección de matrículas en los vehículos y reconocimiento del texto usando OCR.\n",
    "- Conteo total de clases: Recuento acumulativo de cada tipo de objeto detectado.\n",
    "- Exportación de resultados: Generación de un video que visualice los resultados y exportación de un archivo CSV con el detalle de las detecciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import os\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_path):\n",
    "    \"\"\"Initialize the YOLO model for detection.\"\"\"\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def initialize_reader():\n",
    "    \"\"\"Initialize the EasyOCR reader.\"\"\"\n",
    "    return easyocr.Reader(['en'])  \n",
    "\n",
    "def initialize_video_writer(cap, output_video_path):\n",
    "    \"\"\"Set up the video writer for the processed video.\"\"\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    return cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def write_csv_header(csv_file_path):\n",
    "    \"\"\"Prepare CSV file for logging.\"\"\"\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['frame', 'object_type', 'confidence', 'tracking_id', 'x1', 'y1', 'x2', 'y2',\n",
    "                         'license_plate_confidence', 'mx1', 'my1', 'mx2', 'my2', 'license_plate_text'])\n",
    "\n",
    "def put_text(frame, text, position, color=(0, 255, 0), font_scale=0.6, thickness=2, bg_color=(0, 0, 0)):\n",
    "    \"\"\"Helper function to put text with background on the frame.\"\"\"\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
    "    text_x, text_y = position\n",
    "    box_coords = ((text_x, text_y - text_size[1] - 5), (text_x + text_size[0] + 5, text_y + 5))\n",
    "    cv2.rectangle(frame, box_coords[0], box_coords[1], bg_color, cv2.FILLED)\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "video_path = 'C0142.mp4'  # Ruta al video de entrada\n",
    "model_path = 'yolo11n.pt'  # Ruta al modelo YOLO principal\n",
    "license_plate_detector_model_path = 'runs2/detect/train9/weights/best.pt'  # Ruta al modelo detector de matrículas\n",
    "\n",
    "output_video_path = 'output_video.mp4'  # Ruta para guardar el video anotado de salida\n",
    "csv_file_path = 'detection_tracking_log.csv'  # Ruta para guardar el archivo CSV\n",
    "show_video = True  # Establecer en True para mostrar el video mientras se procesa\n",
    "classes_to_detect = [0, 1, 2, 3, 5]  # IDs de clases a detectar\n",
    "\n",
    "# Inicializar el modelo de detección principal\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Inicializar el modelo detector de matrículas\n",
    "license_plate_detector = YOLO(license_plate_detector_model_path)\n",
    "\n",
    "# Inicializar el lector OCR\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "# Configuración del modelo Real-ESRGAN x4 para anime\n",
    "model_esrgan = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
    "                       num_block=6, num_grow_ch=32, scale=4)  # Ajusta 'num_block' a 6 y 'scale' a 4\n",
    "model_path_esrgan = 'RealESRGAN_x4plus_anime_6B.pth'  # Ruta donde guardaste el modelo descargado\n",
    "\n",
    "# Configuración del upsampler con la escala correcta\n",
    "upsampler = RealESRGANer(scale=4, model_path=model_path_esrgan, model=model_esrgan,\n",
    "                         tile=0, tile_pad=10, pre_pad=0, half=False)\n",
    "\n",
    "# Crear una carpeta para las imágenes de las matrículas para debug (opcional)\n",
    "# license_plate_folder = 'license_plates'\n",
    "# if not os.path.exists(license_plate_folder):\n",
    "#     os.makedirs(license_plate_folder)\n",
    "\n",
    "# Abrir el archivo de video y configurar la salida para el video procesado\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Códec\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Inicializar el escritor de video\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Definir nombres y colores de clases para la visualización\n",
    "class_names = {\n",
    "    0: \"person\",\n",
    "    1: \"bicycle\",\n",
    "    2: \"car\",\n",
    "    3: \"motorbike\",\n",
    "    5: \"bus\"\n",
    "}\n",
    "class_colors = {\n",
    "    0: (255, 0, 0),\n",
    "    1: (0, 255, 0),\n",
    "    2: (0, 0, 255),\n",
    "    3: (255, 255, 0),\n",
    "    5: (0, 255, 255)\n",
    "}\n",
    "\n",
    "# Contador total persistente de cada clase a través de todos los fotogramas\n",
    "total_class_count = Counter()\n",
    "# Seguimiento de IDs únicos para cada clase para contar solo una vez\n",
    "seen_ids = defaultdict(set)\n",
    "frame_number = 0  # Inicializar contador de fotogramas\n",
    "\n",
    "# Diccionario para almacenar información de objetos por track_id\n",
    "object_info = {}  # key: track_id, value: dict with info\n",
    "\n",
    "# Variable para controlar la pausa\n",
    "paused = False\n",
    "\n",
    "# Función para colocar texto con fondo\n",
    "def put_text(img, text, position, color=(255, 255, 255), bg_color=(0, 0, 0), font_scale=0.5, thickness=1):\n",
    "    text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "    x, y = position\n",
    "    cv2.rectangle(img, (x, y - text_size[1]), (x + text_size[0], y + text_size[1]//2), bg_color, -1)\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "\n",
    "# Agregar una variable para alternar el desenfoque\n",
    "blur_enabled = True  # Estado inicial: desenfoque habilitado\n",
    "\n",
    "# Bucle a través de cada fotograma\n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        frame_number += 1\n",
    "\n",
    "        # Ejecutar detección y seguimiento con YOLO\n",
    "        results = model.track(frame, persist=True, classes=classes_to_detect)\n",
    "\n",
    "        # Procesar detecciones\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cls = int(box.cls[0])\n",
    "                confidence = round(float(box.conf[0]), 2)\n",
    "\n",
    "                if box.id is not None:\n",
    "                    track_id = int(box.id[0].tolist())\n",
    "                    if track_id not in seen_ids[cls]:\n",
    "                        seen_ids[cls].add(track_id)\n",
    "                        total_class_count[class_names[cls]] += 1\n",
    "\n",
    "                    # Inicializar o actualizar información del objeto\n",
    "                    if track_id not in object_info:\n",
    "                        object_info[track_id] = {\n",
    "                            'class_name': class_names[cls],\n",
    "                            'max_confidence': confidence,\n",
    "                            'first_frame': frame_number,\n",
    "                            'last_frame': frame_number,\n",
    "                            'bounding_box': (x1, y1, x2, y2),\n",
    "                            'license_plate_text': '',\n",
    "                            'plate_confidence': None,\n",
    "                            'plate_bounding_box': (None, None, None, None),\n",
    "                            'license_plate_filename': '',\n",
    "                        }\n",
    "                    else:\n",
    "                        info = object_info[track_id]\n",
    "                        info['last_frame'] = frame_number\n",
    "                        if confidence > info['max_confidence']:\n",
    "                            info['max_confidence'] = confidence\n",
    "                            info['bounding_box'] = (x1, y1, x2, y2)\n",
    "\n",
    "                    # Dibujar el cuadro delimitador y la etiqueta\n",
    "                    color = class_colors.get(cls, (0, 255, 0))\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "                    put_text(frame, f\"{class_names[cls]} {confidence}\", (x1, y1 - 10), color=(255, 255, 255))\n",
    "                    put_text(frame, f\"ID: {track_id}\", (x1, y2 + 20), color=(255, 255, 255))\n",
    "\n",
    "                    # Reconocimiento de matrículas para vehículos\n",
    "                    if class_names[cls] in [\"car\", \"motorbike\", \"bus\"]:\n",
    "                        vehicle_img = frame[y1:y2, x1:x2]  # Recortar el área del vehículo\n",
    "\n",
    "                        # Verificar si la imagen recortada es lo suficientemente grande\n",
    "                        min_vehicle_size = 100\n",
    "                        if vehicle_img.shape[0] < min_vehicle_size or vehicle_img.shape[1] < min_vehicle_size:\n",
    "                            continue\n",
    "\n",
    "                        # Verificar si la confianza es lo suficientemente alta\n",
    "                        if confidence < 0.7:\n",
    "                            continue\n",
    "\n",
    "                        # Ejecutar el modelo detector de matrículas en la imagen del vehículo\n",
    "                        plate_results = license_plate_detector.predict(vehicle_img)\n",
    "\n",
    "                        # Procesar resultados de detección de matrículas\n",
    "                        if plate_results and len(plate_results[0].boxes) > 0:\n",
    "                            for plate_box in plate_results[0].boxes:\n",
    "                                # Obtener coordenadas ajustadas al fotograma\n",
    "                                px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                                px1, py1, px2, py2 = px1 + x1, py1 + y1, px2 + x1, py2 + y1\n",
    "\n",
    "                                # Verificar tamaño mínimo de la matrícula\n",
    "                                min_plate_width = 50\n",
    "                                min_plate_height = 15\n",
    "                                if (px2 - px1) < min_plate_width or (py2 - py1) < min_plate_height:\n",
    "                                    continue  # Ignorar matrículas demasiado pequeñas\n",
    "\n",
    "                                # Extraer la ROI de la matrícula\n",
    "                                license_plate_roi = frame[py1:py2, px1:px2]\n",
    "\n",
    "                                # Escalar la imagen usando Real-ESRGAN\n",
    "                                try:\n",
    "                                    output, _ = upsampler.enhance(np.array(license_plate_roi), outscale=4)\n",
    "                                    enhanced_license_plate = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Ocurrió un error durante la mejora de la imagen: {e}\")\n",
    "                                    enhanced_license_plate = license_plate_roi  # Usar la imagen original si falla\n",
    "\n",
    "                                # Guardamos la imagen para debug (opcional)\n",
    "                                # license_plate_filename = f\"{license_plate_folder}/plate_frame{frame_number}_id{track_id}.png\"\n",
    "                                # cv2.imwrite(license_plate_filename, enhanced_license_plate)\n",
    "\n",
    "                                # Aplicamos OCR\n",
    "                                plate_ocr_results = reader.readtext(enhanced_license_plate, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "                                if plate_ocr_results:\n",
    "                                    license_plate_text = plate_ocr_results[0][-2]\n",
    "                                    plate_confidence = round(plate_ocr_results[0][-1], 2)\n",
    "                                    mx1, my1, mx2, my2 = px1, py1, px2, py2\n",
    "\n",
    "                                    # Actualizar información en object_info\n",
    "                                    if (object_info[track_id]['plate_confidence'] is None or\n",
    "                                        plate_confidence > object_info[track_id]['plate_confidence']):\n",
    "                                        object_info[track_id]['license_plate_text'] = license_plate_text\n",
    "                                        object_info[track_id]['plate_confidence'] = plate_confidence\n",
    "                                        object_info[track_id]['plate_bounding_box'] = (mx1, my1, mx2, my2)\n",
    "                                        # object_info[track_id]['license_plate_filename'] = license_plate_filename\n",
    "\n",
    "                                    # Dibujar el cuadro delimitador para la matrícula\n",
    "                                    background_color = (255, 255, 255)  # Fondo blanco para contraste\n",
    "                                    cv2.rectangle(frame, (px1, py1), (px2, py2), background_color, 2)\n",
    "\n",
    "                                    # Mostrar el texto de la matrícula con mayor confianza\n",
    "                                    best_license_plate_text = object_info[track_id]['license_plate_text']\n",
    "                                    high_contrast_color = (0, 0, 0)  # Texto negro\n",
    "                                    put_text(frame, f\"Plate: {best_license_plate_text}\", (px1, py2 + 20), color=high_contrast_color, bg_color=background_color)\n",
    "                                else:\n",
    "                                    # Sin resultados OCR\n",
    "                                    pass\n",
    "                                \n",
    "                                # Anonimización de matrícula si está habilitado\n",
    "                                if blur_enabled:\n",
    "                                    license_plate_roi = frame[py1:py2, px1:px2]\n",
    "                                    blurred_license_plate = cv2.GaussianBlur(license_plate_roi, (51, 51), 30)\n",
    "                                    frame[py1:py2, px1:px2] = blurred_license_plate\n",
    "\n",
    "                    # Anonimización condicional de personas\n",
    "                    if class_names[cls] == \"person\" and blur_enabled:\n",
    "                        person_roi = frame[y1:y2, x1:x2]\n",
    "                        blurred_person = cv2.GaussianBlur(person_roi, (51, 51), 30)\n",
    "                        frame[y1:y2, x1:x2] = blurred_person\n",
    "                        \n",
    "        # Mostrar contadores y FPS\n",
    "        y_offset = 30\n",
    "        for cls, count in total_class_count.items():\n",
    "            put_text(frame, f\"Total {cls}: {count}\", (10, y_offset))\n",
    "            y_offset += 20\n",
    "\n",
    "        fps_calc = 1.0 / (time.time() - start_time)\n",
    "        put_text(frame, f\"FPS: {fps_calc:.2f}\", (10, y_offset), color=(255, 255, 255))\n",
    "\n",
    "        # Escribir el fotograma en el video de salida\n",
    "        out.write(frame)\n",
    "\n",
    "    # Mostrar el fotograma (opcional)\n",
    "    if show_video:\n",
    "        cv2.imshow('Detection and Tracking', frame)\n",
    "        # Manejo de teclas\n",
    "        key = cv2.waitKey(1 if not paused else 0) & 0xFF\n",
    "        if key == 27:  # Tecla Escape\n",
    "            break\n",
    "        elif key == ord(' '):  # Tecla Espacio\n",
    "            paused = not paused\n",
    "        elif key == ord('b'):  # Tecla para alternar desenfoque\n",
    "            blur_enabled = not blur_enabled  # Cambia el estado de desenfoque\n",
    "            print(f\"Desenfoque {'habilitado' if blur_enabled else 'deshabilitado'}\")\n",
    "\n",
    "# Después de procesar todos los fotogramas, escribir al CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['track_id', 'class', 'max_confidence', 'first_frame', 'last_frame',\n",
    "                     'x1', 'y1', 'x2', 'y2', 'plate_confidence', 'mx1', 'my1', 'mx2', 'my2',\n",
    "                     'license_plate_text', 'license_plate_image'])\n",
    "    for track_id, info in object_info.items():\n",
    "        writer.writerow([\n",
    "            track_id,\n",
    "            info['class_name'],\n",
    "            info['max_confidence'],\n",
    "            info['first_frame'],\n",
    "            info['last_frame'],\n",
    "            *info['bounding_box'],\n",
    "            info['plate_confidence'],\n",
    "            *(info['plate_bounding_box']),\n",
    "            info['license_plate_text'],\n",
    "            info['license_plate_filename'],\n",
    "        ])\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Esta sección se presentan los resultados obtenidos. Cargaremos el archivo CSV para revisar el recuento total de cada tipo de objeto detectado, así como los detalles de las detecciones de matrículas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV de resultados\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.read_csv('detection_tracking_log.csv')\n",
    "print(\"Resumen de detecciones por clase:\")\n",
    "print(results_df['class'].value_counts())\n",
    "\n",
    "print(\"\\nEjemplo de datos de detección de matrículas:\")\n",
    "display(results_df[results_df['class'] == 'car'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En esta práctica se ha desarrollado un prototipo funcional que permite:\n",
    "\n",
    "- Detectar y seguir personas y vehículos en video.\n",
    "- Detectar y leer matrículas en vehículos mediante un modelo YOLO y OCR.\n",
    "- Exportar los resultados visuales en un video y los datos de detección en un archivo CSV.\n",
    "\n",
    "Este prototipo constituye una herramienta útil para el análisis automatizado de video en aplicaciones de monitoreo y seguridad, con posibilidad de mejoras futuras en el rendimiento y precisión del OCR de matrículas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
